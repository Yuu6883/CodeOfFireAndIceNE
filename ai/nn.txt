We will use evolution for the nn instead of using gradient

The bot will have 2 - 4 nn attached (depends on which league):
    1 for training units
    2 for moving units
    3 for building mine
    4 for building tower

Training agent:
    Input dimension: 17
    Inputs: [8 surrounding cell, x, y, 
        player_income, player_gold, player_uni_num, 
        enemy_income, enemy_gold, enemy_unit_num, 
        turns]
    Cell encoding: VOID -> -1, NEUTRAL -> 0, 
        Enemy_tower -> -0.5, Enemy_mine -> -0.25 Enemy_unit -> -1 / level, Enemy_active -> -0.1, Enemy_inactive -> -0.05
        Player_tower -> 0.5, Player_mine -> 0.25, Player_unit -> 1 / level, Player_active -> 0.1, Player_inactive?? -> 0.05
    Output: softmax([should_not_train, should_train_level_1, should_train_level_2, should_train_level_3])

Moving agent:
    Input dimension: 12
    Inputs: [8 surrounding cell, level, x, y, turn]
    Cell encoding: same as training agent
    Output: softmax([up, right, down, left, stay])

Mine building agent:
    Input dimentsion: 13
    Inputs: [8 surrounding cell, x, y, player_mine_number, player_gold, player_income]
    Cell encoding: same as training agent
    Output: probability?
    Output interpretation:
        [0 - 1] -> build mine
        [-1 - 0] -> do not build mine

Tower building agent:
    Input dimension: 13
    Inputs: [8 surrounding cell, x, y, player_tower_number, player_gold, player_income]
    Cell encoding: same as training agent
    Output: probability?
    Output interpretation:
        [0 - 1] -> build tower
        [-1 - 0] -> do not build tower
    